{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36351d69-f1d8-4dc2-9dcc-c6150f58305d",
   "metadata": {},
   "source": [
    "# Native-Sparse-Attention\n",
    "\n",
    "author: [dhcode-cpp](https://github.com/dhcode-cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe0abf-e68a-4539-af9b-fa8de9b67985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36100c16-1bae-48d2-b69d-314bb8756db6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "290207c6-4aeb-4a0c-9394-1b11b42f97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 32 # token ids \n",
    "l = 8 # block\n",
    "d = 8 # sliding stride\n",
    "block_nums = t // l\n",
    "dim = 16 # embeddin dimension\n",
    "heads = 4\n",
    "head_dim = dim//heads\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d430aca-12dc-49db-a5f9-17553de1ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(batch_size, t, dim)\n",
    "\n",
    "Wq = torch.randn(dim, dim)\n",
    "Wk = torch.randn(dim, dim)\n",
    "Wv = torch.randn(dim, dim)\n",
    "\n",
    "Q = X @ Wq\n",
    "K = X @ Wk\n",
    "V = X @ Wv\n",
    "\n",
    "# skip apply rope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb2f67fa-4a71-4611-b811-29e8236dd49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 16])\n",
      "torch.Size([1, 32, 16])\n",
      "torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "print(Q.shape)\n",
    "print(K.shape)\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e90e6-313d-462c-9e5e-70de459176a8",
   "metadata": {},
   "source": [
    "## Attention with different KV-len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac0ffd-d6ec-423a-8af7-80b34c96a463",
   "metadata": {},
   "source": [
    "## Token Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1ba786d1-ea69-4252-91da-cf1bdecef1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor([ 1,  5,  9, 13, 17, 21])\n",
      "tensor([ 8, 12, 16, 20, 24, 28])\n"
     ]
    }
   ],
   "source": [
    "d = 4\n",
    "max_idx = round(( t - l ) / d)\n",
    "print(max_idx)\n",
    "print(torch.arange(max_idx) * d + 1)\n",
    "print(torch.arange(max_idx) * d + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ee4464bb-26bc-499b-a91c-8f9cc757f017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "tensor([ 1,  9, 17, 25])\n",
      "tensor([ 8, 16, 24, 32])\n"
     ]
    }
   ],
   "source": [
    "d = l\n",
    "max_idx = round(( t ) / d)\n",
    "print(max_idx)\n",
    "print(torch.arange(max_idx) * d + 1)\n",
    "print(torch.arange(max_idx) * d + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff27d753-9762-4daa-be59-4ee312cf4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K_cmp = torch.randn(l, 1)\n",
    "W_V_cmp = torch.randn(l, 1)\n",
    "W_pe = torch.randn(l, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec4efec5-117d-456f-99e4-93cfe1344491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[:, i * d + 0: i * d + l  , :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed893036-f661-485f-81b1-317a97774d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 16])\n",
      "torch.Size([1, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "K_cmp = []\n",
    "V_cmp = []\n",
    "for i in range(max_idx):\n",
    "    cur_K = K[:, i * d + 0: i * d + l , :] + W_pe.unsqueeze(0)\n",
    "    cur_V = V[:, i * d + 0: i * d + l , :] + W_pe.unsqueeze(0)\n",
    "    cur_K = cur_K.transpose(1, 2) @ W_K_cmp \n",
    "    cur_V = cur_V.transpose(1, 2) @ W_V_cmp\n",
    "    K_cmp.append(cur_K)\n",
    "    V_cmp.append(cur_V)\n",
    "\n",
    "K_cmp = torch.cat(K_cmp, dim = 2).transpose(1,2)\n",
    "V_cmp = torch.cat(V_cmp, dim = 2).transpose(1,2)\n",
    "print(K_cmp.shape)\n",
    "print(V_cmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9c61bd97-9da2-4b22-bc04-e8e5b5f5664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "# 多头注意力版本\n",
    "Q_mha = Q.view(1, t, heads, head_dim).transpose(1,2)\n",
    "K_cmp_mha = K_cmp.view(1, block_nums, heads, head_dim).transpose(1,2)\n",
    "V_cmp_mha = V_cmp.view(1, block_nums, heads, head_dim).transpose(1,2)\n",
    "score_cmp = Q_mha @ K_cmp_mha.transpose(2,3) # bs, head, q_len, k_cmp_len\n",
    "print(score_cmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f8f8588f-afd6-400d-9511-354c58818db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 32, 4])\n",
      "torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "p_cmp = F.softmax(score_cmp, dim = -1) \n",
    "o_cmp = p_cmp @ V_cmp_mha\n",
    "print(o_cmp.shape)\n",
    "\n",
    "o_cmp = o_cmp.transpose(2, 1).reshape(batch_size, t, dim)\n",
    "print(o_cmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001f394-39a0-44cb-98a7-57658e174045",
   "metadata": {},
   "source": [
    "## Token Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "614e156d-359c-460b-9a2f-4b4bfc7cfdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 32, 4])\n",
      "torch.Size([1, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "print(p_cmp.shape)\n",
    "p_slc = p_cmp.sum(dim = 1)\n",
    "print(p_slc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e058a6cb-741b-41c1-9b8c-41bb59aa6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_top_k = 2\n",
    "value, idx = torch.topk(p_slc, dim = 2, k = select_top_k)\n",
    "print(key[0,0,:])\n",
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1970036f-a955-4914-afad-3e437ad6fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 16])\n",
      "torch.Size([1, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "idx_slc_start = idx * d\n",
    "idx_slc_end = idx * d + l\n",
    "K_slc = torch.randn(batch_size, d * select_top_k, dim)\n",
    "V_slc = torch.randn(batch_size, d * select_top_k, dim)\n",
    "for i in range(batch_size):\n",
    "    for j in range(t):\n",
    "        for k in range(select_top_k):\n",
    "            K_slc[i, k * d : k * d + l, :] = K[i, idx_slc_start[i, j, k ] :  idx_slc_end[i, j, k ] , :]\n",
    "            V_slc[i, k * d : k * d + l, :] = V[i, idx_slc_start[i, j, k ] :  idx_slc_end[i, j, k ] , :]\n",
    "print(K_slc.shape)\n",
    "print(V_slc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2cb3166a-2400-4286-bce1-e35610b18c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16, 4])\n",
      "torch.Size([1, 1, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "V_slc_mha = V_slc.view(batch_size, select_top_k * d, heads, head_dim).transpose(1,2)\n",
    "V_slc = V_slc_mha.sum(dim = 1, keepdim = True)\n",
    "print(V_slc.shape)\n",
    "\n",
    "K_slc_mha = K_slc.view(1, select_top_k * d, heads, head_dim).transpose(1,2)\n",
    "K_slc = K_slc_mha.sum(dim = 1, keepdim = True)\n",
    "print(V_slc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cdf6cd1c-2b3f-4a60-a143-04d0e8f3f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 32, 16])\n",
      "torch.Size([1, 4, 32, 16])\n",
      "torch.Size([1, 4, 16, 4])\n",
      "torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "# 多头注意力版本\n",
    "score_cls = Q_mha @ K_slc.transpose(2,3).repeat(1, heads, 1, 1) # bs, head, q_len, 8282\n",
    "print(score_cls.shape)\n",
    "p_slc = F.softmax(score_cls, dim = -1) \n",
    "print(p_cls.shape)\n",
    "\n",
    "V_slc_onehead = V_slc.repeat(1, heads, 1, 1)\n",
    "print(V_slc_onehead.shape)\n",
    "\n",
    "o_slc = p_slc @ V_slc_onehead # bs, seq, dim   \n",
    "print(o_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cfc639b4-cac5-439b-995c-b30b5567eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "o_slc = o_slc.transpose(2, 1).reshape(batch_size, t, dim)\n",
    "print(o_cls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edae1df-bf98-4d67-81ca-ef7b6a24e359",
   "metadata": {},
   "source": [
    "## window attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "28c377f6-2ae3-4b78-87a6-5a63c7b20aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "torch.Size([1, 8, 16])\n",
      "torch.Size([1, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "window = 8\n",
    "t_idxs = torch.arange(t)\n",
    "print(t_idxs)\n",
    "\n",
    "K_win = torch.randn(batch_size, window, dim)\n",
    "V_win = torch.randn(batch_size, window, dim)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    idx_start = i - window\n",
    "    if idx_start < 0:\n",
    "        idx_start = 0  \n",
    "    K_win[i, :, :] = K[i, idx_start : idx_start + window , :]\n",
    "    V_win[i, :, :] = V[i, idx_start : idx_start + window , :]\n",
    "print(K_win.shape)\n",
    "print(V_win.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "37efa397-d24b-40b2-b20b-aae53eb97d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "# 我们简化注意力计算\n",
    "S = Q @ K_win.transpose(1,2)\n",
    "o_win = S @ V_win\n",
    "print(o_win.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4c1b1-e5e8-4faf-99e3-b33952c6739b",
   "metadata": {},
   "source": [
    "## Gated Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9a48287f-a31b-4dc1-a05f-d9681d0560ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "W_gated = torch.randn(dim, 3) # 3: cmp, slc, win\n",
    "gate = X @ W_gated\n",
    "gate = F.sigmoid(gate)\n",
    "print(gate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0d180fc2-250e-4d06-ad14-deca69fef6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "o_list = [o_cmp, o_slc, o_win]\n",
    "o_star = torch.zeros(batch_size, t, dim)\n",
    "for i in range(3):\n",
    "    o_star += gate[:, :, i].unsqueeze(2) * o_list[i]\n",
    "print(o_star.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
